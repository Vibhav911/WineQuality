{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vibhav911/Documents/skills/Data Science/DS_Projects/WineQuality/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vibhav911/Documents/skills/Data Science/DS_Projects/WineQuality'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "os.environ['MLFLOW_TRACKING_URI'] = \"https://dagshub.com/Vibhav911/WineQuality.mlflow\"\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'Vibhav911'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'da4547942d0e21905b789c56015bd7f201f66d4e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity program\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    test_data_path: Path\n",
    "    model_path : Path\n",
    "    all_params: dict\n",
    "    metric_file_name: Path\n",
    "    target_column: str\n",
    "    mlflow_uri: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WineQProject.constants import *\n",
    "from WineQProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Manager\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        params = self.params.ElasticNet\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            test_data_path = config.test_data_path,\n",
    "            model_path = config.model_path,\n",
    "            all_params = params,\n",
    "            metric_file_name = config.metric_file_name,\n",
    "            target_column = schema.name,\n",
    "            mlflow_uri = 'https://dagshub.com/Vibhav911/WineQuality.mlflow'\n",
    "        )\n",
    "        \n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import joblib\n",
    "from WineQProject.utils.common import save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, config=ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "        \n",
    "    def eval_metric(self, actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2\n",
    "    \n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        model = joblib.load(self.config.model_path)\n",
    "        \n",
    "        test_x = test_data.drop([self.config.target_column], axis = 1)\n",
    "        test_y = test_data[[self.config.target_column]]\n",
    "        \n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)    # settting tracking uri as doing in the remote server\n",
    "        tracking_uri_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            predicted_qualities = model.predict(test_x.values)\n",
    "            (rmse, mae, r2) = self.eval_metric(test_y.values, predicted_qualities)\n",
    "            \n",
    "            #Saving metric as local\n",
    "            scores={'rmse':rmse, 'mae':mae, 'r2':r2}\n",
    "            save_json(path=Path(self.config.metric_file_name), data=scores)\n",
    "            \n",
    "            mlflow.log_params(self.config.all_params)    # saving in mlflow\n",
    "            mlflow.log_metric('rmse', rmse)\n",
    "            mlflow.log_metric('r2', r2)\n",
    "            mlflow.log_metric('mae', mae)\n",
    "            \n",
    "            \n",
    "            # Check if you are working in uri or local file\n",
    "            # model registry does not work with file store\n",
    "            if tracking_uri_type_store != 'file':\n",
    "                \n",
    "                # Register the model\n",
    "                # There are other way to use the Model Registry, which depends on the use case, \n",
    "                # please refer to the document for more information:\n",
    "                # https://www.mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.sklearn.log_model(model, 'model', registered_model_name=\"ElasticnetModel\")\n",
    "            \n",
    "            else:\n",
    "                mlflow.sklearn.log_model(model,'model')\n",
    "                \n",
    "                # Save the model to the model registry\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-20 06:40:11,175: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-05-20 06:40:11,177: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-05-20 06:40:11,180: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-05-20 06:40:11,181: INFO: common: created directory at: artifacts]\n",
      "[2024-05-20 06:40:11,182: INFO: common: created directory at: artifacts/model_evaluation]\n",
      "[2024-05-20 06:40:11,206: WARNING: connectionpool: Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /Vibhav911/WineQuality.mlflow/api/2.0/mlflow/runs/create]\n",
      "[2024-05-20 06:40:11,822: INFO: common: json file saved at: artifacts/model_evaluation/metrics.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vibhav911/Documents/skills/Data Science/DS_Projects/WineQuality/winequality_envp03/lib/python3.10/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/vibhav911/Documents/skills/Data Science/DS_Projects/WineQuality/winequality_envp03/lib/python3.10/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'ElasticnetModel' already exists. Creating a new version of this model...\n",
      "2024/05/20 06:40:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ElasticnetModel, version 3\n",
      "Created version '3' of model 'ElasticnetModel'.\n"
     ]
    }
   ],
   "source": [
    "# pipeline\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    model_evaluation_config = ModelEvaluation(config=model_evaluation_config)\n",
    "    model_evaluation_config.log_into_mlflow()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winequality_envp03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
